{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers torch pillow pandas matplotlib\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedfaa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# BLIP VQA model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-vqa-base\").to(device)\n",
    "\n",
    "print(\"âœ… Model BLIP VQA loaded on\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e942aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vqa_question.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    q_data = json.load(f)\n",
    "\n",
    "questions = q_data[\"questions\"]\n",
    "print(\"Daftar pertanyaan VQA:\", questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"dataset_eval/\"\n",
    "results = []\n",
    "\n",
    "for exp in os.listdir(base_dir):\n",
    "    exp_path = os.path.join(base_dir, exp)\n",
    "    if not os.path.isdir(exp_path):\n",
    "        continue\n",
    "    \n",
    "    for img_file in os.listdir(exp_path):\n",
    "        if not img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            continue\n",
    "        \n",
    "        img_path = os.path.join(exp_path, img_file)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        for q in questions:\n",
    "            inputs = processor(image, q, return_tensors=\"pt\").to(device)\n",
    "            out = model.generate(**inputs)\n",
    "            answer = processor.decode(out[0], skip_special_tokens=True)\n",
    "            \n",
    "            results.append({\n",
    "                \"experiment\": exp,\n",
    "                \"image\": img_file,\n",
    "                \"question\": q,\n",
    "                \"answer\": answer\n",
    "            })\n",
    "\n",
    "df_vqa = pd.DataFrame(results)\n",
    "df_vqa.to_csv(\"vqa_results.csv\", index=False)\n",
    "df_vqa.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492715d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan ringkasan jawaban\n",
    "summary = df_vqa.groupby([\"experiment\", \"question\"])[\"answer\"].apply(lambda x: x.value_counts().index[0]).reset_index()\n",
    "\n",
    "print(\"Ringkasan jawaban per eksperimen & pertanyaan:\")\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed886fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter pertanyaan tertentu\n",
    "q_filter = \"Apakah terdapat teks onomatope di dalam gambar?\"\n",
    "subset = df_vqa[df_vqa[\"question\"] == q_filter]\n",
    "\n",
    "count_answers = subset.groupby([\"experiment\", \"answer\"]).size().unstack(fill_value=0)\n",
    "\n",
    "count_answers.plot(kind=\"bar\", stacked=True, figsize=(10,6))\n",
    "plt.title(\"Distribusi Jawaban VQA per Eksperimen\")\n",
    "plt.ylabel(\"Jumlah Gambar\")\n",
    "plt.xlabel(\"Eksperimen\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Jawaban\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil contoh 1 gambar per eksperimen dengan jawaban VQA\n",
    "sample = df_vqa.groupby(\"experiment\").first().reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(sample), figsize=(15,5))\n",
    "for i, row in enumerate(sample.itertuples()):\n",
    "    img_path = os.path.join(base_dir, row.experiment, row.image)\n",
    "    img = Image.open(img_path)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"{row.experiment}\\n{row.answer[:15]}...\")\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
