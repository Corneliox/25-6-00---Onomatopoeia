# -*- coding: utf-8 -*-
"""Onomatopoeia Interface Gradio Demo

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10dHxpBY9FlHh3dk4bYP-f3hvelOMtcKb
"""

# -*- coding: utf-8 -*-
"""
Onomatopoeia Interface Gradio Demo
A Gradio interface for Stable Diffusion 1.5 text-to-image generation
with custom models and LoRA support.
"""

# Import libraries
import gradio as gr
import torch
from diffusers import (StableDiffusionPipeline, EulerDiscreteScheduler, DDIMScheduler, 
                       UniPCMultistepScheduler, DPMSolverMultistepScheduler, 
                       HeunDiscreteScheduler, EulerAncestralDiscreteScheduler, 
                       DPMSolverSinglestepScheduler)
import os
import requests
import zipfile
from datetime import datetime

# --- Constants and Setup ---
# Create a directory for outputs if it doesn't exist
os.makedirs("outputs", exist_ok=True)

# Dictionary to map friendly names to model URLs
CHECKPOINT_MAP = {
    "dreamshaper_8": "https://civitai.com/api/download/models/128713",
    "rev_animated": "https://civitai.com/api/download/models/425083",
    "toonyou": "https://civitai.com/api/download/models/125771"
}

# Dictionary to map friendly names to LoRA URLs
LORA_MAP = {
    "3050_v2": "https://huggingface.co/Corneliox/LoraOnomatopoeia/resolve/main/3050%20v2.safetensors",
    "final2050": "https://huggingface.co/Corneliox/LoraOnomatopoeia/resolve/main/Final2050.safetensors",
    "final3050": "https://huggingface.co/Corneliox/LoraOnomatopoeia/resolve/main/final3050.safetensors"
}

# Create a directory for outputs if it doesn't exist
os.makedirs("outputs", exist_ok=True)

# Dictionary to map friendly names to model URLs
checkpoint_map = {
    "dreamshaper_8": "https://civitai.com/api/download/models/128713?token=ecac6e303a453279ffddc9c7aaf16cce&type=Model&format=SafeTensor&size=pruned&fp=fp16",
    "rev_animated": "https://civitai.com/api/download/models/425083?token=ecac6e303a453279ffddc9c7aaf16cce&type=Model&format=SafeTensor&size=full&fp=fp16",
    "toonyou": "https://civitai.com/api/download/models/125771?token=ecac6e303a453279ffddc9c7aaf16cce&type=Model&format=SafeTensor&size=pruned&fp=fp16"
}

# Dictionary to map friendly names to LoRA URLs
lora_map = {
    "3050_v2": "https://huggingface.co/Corneliox/LoraOnomatopoeia/resolve/main/3050%20v2.safetensors",
    "final2050": "https://huggingface.co/Corneliox/LoraOnomatopoeia/resolve/main/Final2050.safetensors",
    "final3050": "https://huggingface.co/Corneliox/LoraOnomatopoeia/resolve/main/final3050.safetensors"
}

# --- Utility Functions ---
def download_file(url, save_dir, file_name):
    """Downloads a file from a URL and saves it."""
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    file_path = os.path.join(save_dir, file_name)
    if not os.path.exists(file_path):
        print(f"Downloading {file_name} from {url}...")
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            print(f"Downloaded {file_name} successfully.")
        except requests.exceptions.RequestException as e:
            print(f"Error downloading {file_name}: {e}")
            return None
    else:
        print(f"{file_name} already exists.")
    return file_path

# --- Global Variables ---
pipe = None
current_checkpoint_path = ""
current_lora_path = ""

# --- Core Image Generation Function ---
def generate_image(
    checkpoint_name, custom_checkpoint_url,
    lora_name, strength_model, strength_clip,
    positive_prompt, negative_prompt,
    width, height, batch_size,
    seed_value, control_after_generate,
    steps, cfg,
    sampler_name, scheduler_name, denoise,
    device_choice
):
    global pipe, current_checkpoint_path, current_lora_path

    if device_choice == "CPU":
        device = "cpu"
        torch_dtype = torch.float32
    else:
        device = "cuda"
        torch_dtype = torch.float16

    # --- 1. Load Checkpoint ---
    if custom_checkpoint_url:
        checkpoint_filename = custom_checkpoint_url.split('/')[-1].split('?')[0]
        model_path = download_file(custom_checkpoint_url, "./checkpoints", checkpoint_filename)
    else:
        model_url = checkpoint_map[checkpoint_name]
        checkpoint_filename = f"{checkpoint_name}.safetensors"
        model_path = download_file(model_url, "./checkpoints", checkpoint_filename)

    if not model_path:
        error_msg = "Gagal mengunduh checkpoint."
        return None, gr.update(), gr.update(visible=False), error_msg

    # Load pipeline only if the checkpoint has changed
    if model_path != current_checkpoint_path:
        print(f"Loading new checkpoint: {model_path}")
        try:
            pipe = StableDiffusionPipeline.from_single_file(
                model_path,
                torch_dtype=torch_dtype,
                use_safetensors=True
            ).to(device)
            current_checkpoint_path = model_path
            current_lora_path = "" # Reset LoRA when checkpoint changes
        except Exception as e:
            error_msg = f"Error loading pipeline: {e}"
            return None, gr.update(), gr.update(visible=False), error_msg

    # --- 2. Load and Fuse LoRA ---
    if lora_name:
        lora_url = lora_map[lora_name]
        lora_filename = lora_url.split('/')[-1]
        lora_path = download_file(lora_url, "./loras", lora_filename)

        if not lora_path:
            error_msg = "Gagal mengunduh LoRA."
            return None, gr.update(), gr.update(visible=False), error_msg

        if lora_path != current_lora_path:
            print(f"Unloading previous LoRAs and loading new one: {lora_path}")
            pipe.unload_lora_weights()
            try:
                 pipe.load_lora_weights(os.path.dirname(lora_path), weight_name=os.path.basename(lora_path))
                 current_lora_path = lora_path
            except Exception as e:
                 print(f"Could not load LoRA with diffusers. Attempting state_dict load. Error: {e}")
                 try:
                    pipe.load_lora_weights(lora_path)
                    current_lora_path = lora_path
                 except Exception as e2:
                    error_msg = f"Failed to load LoRA weights: {e2}"
                    return None, gr.update(), gr.update(visible=False), error_msg

        print(f"Fusing LoRA with model strength {strength_model} and clip strength {strength_clip}")
        pipe.fuse_lora(lora_scale=strength_model)


    # --- 3. Set Sampler/Scheduler ---
    if scheduler_name == "karras":
        if sampler_name in ["dpmpp_2m", "dpmpp_2m_sde"]:
             pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config, use_karras_sigmas=True)
        elif sampler_name == "euler_ancestral":
            pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)
        else:
            pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)
    elif scheduler_name == "simple":
         pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)
    elif scheduler_name == "exponential":
         pipe.scheduler = DPMSolverSinglestepScheduler.from_config(pipe.scheduler.config)
    else:
        pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)
    print(f"Using Scheduler: {pipe.scheduler.__class__.__name__}")


    # --- 4. Generate Image ---
    generator = torch.Generator(device).manual_seed(int(seed_value))

    images = pipe(
        prompt=positive_prompt,
        negative_prompt=negative_prompt,
        width=width,
        height=height,
        num_inference_steps=steps,
        guidance_scale=cfg,
        num_images_per_prompt=batch_size,
        generator=generator,
    ).images

    # --- 5. Save images and prepare output ---
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    batch_dir = os.path.join("outputs", timestamp)
    os.makedirs(batch_dir)
    image_paths = []
    for i, img in enumerate(images):
        # Use a unique name for each image file
        file_path = os.path.join(batch_dir, f"image_{i+1}_seed{seed_value}.png")
        img.save(file_path)
        image_paths.append(file_path)

    # --- 6. Zip images if batch size > 1 ---
    zip_file_output = gr.update(visible=False) # Hide by default
    if len(image_paths) > 1:
        zip_path = os.path.join(batch_dir, "batch_images.zip")
        with zipfile.ZipFile(zip_path, 'w') as zf:
            for file in image_paths:
                zf.write(file, arcname=os.path.basename(file))
        zip_file_output = gr.update(value=zip_path, visible=True)

    # --- 7. Handle Seed Control ---
    if control_after_generate == 'increment':
        seed_value += 1
    elif control_after_generate == 'decrement':
        seed_value -= 1
    elif control_after_generate == 'randomize':
        seed_value = -1 # Gradio's special value for random

    status_update = f"Berhasil menghasilkan {len(image_paths)} gambar di folder: {batch_dir}"
    return image_paths, gr.update(value=seed_value), zip_file_output, status_update


# --- Gradio UI ---
with gr.Blocks(css="""#col-container {margin: 0 auto; max-width: 800px;}""") as demo:
    gr.Markdown("# Stable Diffusion 1.5 Text-to-Image (Batch Mode)")
    gr.Markdown("UI berdasarkan alur kerja ComfyUI yang disediakan. Sekarang dengan opsi unduh per gambar dan unduh semua sebagai .zip.")

    with gr.Row():
        # --- LEFT COLUMN (SETTINGS) ---
        with gr.Column(scale=2):
            with gr.Accordion("1. Model & LoRA", open=True):
                checkpoint_name = gr.Dropdown(
                    list(checkpoint_map.keys()),
                    value="dreamshaper_8",
                    label="Pilih Checkpoint"
                )
                custom_checkpoint_url = gr.Textbox(
                    label="Atau masukkan URL Checkpoint kustom (.safetensors)"
                )
                lora_name = gr.Dropdown(
                    list(lora_map.keys()),
                    value="3050_v2",
                    label="Pilih LoRA"
                )
                strength_model = gr.Slider(
                    minimum=0, maximum=2, step=0.05, value=0.8,
                    label="Strength Model (Lora)"
                )
                strength_clip = gr.Slider(
                    minimum=0, maximum=2, step=0.05, value=0.8,
                    label="Strength Clip (Lora)"
                )
                device_choice = gr.Dropdown([
                    "GPU", "CPU"
                ], value="GPU", label="Device (GPU/CPU)")

            with gr.Accordion("2. Prompts", open=True):
                positive_prompt = gr.Textbox(
                    value='onomatopeia_style, Onomatopoeia, hitam, abu-abu, Timbre, "duut", San-serif, Tebal, keras, berisik',
                    label="Positive Prompt", lines=3
                )
                negative_prompt = gr.Textbox(
                    value='(worst quality, low quality:1.4), blurry, text, watermark, signature, deformed',
                    label="Negative Prompt", lines=3
                )

            with gr.Accordion("3. Image & Batch Size", open=True):
                 width = gr.Slider(
                    minimum=512, maximum=1024, step=64, value=512,
                    label="Lebar (Width)"
                )
                 height = gr.Slider(
                    minimum=512, maximum=1024, step=64, value=512,
                    label="Tinggi (Height)"
                )
                 batch_size = gr.Slider(
                    minimum=1, maximum=16, step=1, value=1,
                    label="Batch Size (Jumlah Gambar)"
                )

            with gr.Accordion("4. Sampler & Scheduler", open=True):
                with gr.Row():
                    seed_value = gr.Number(
                        value=797042917871481, label="Seed", precision=0
                    )
                    control_after_generate = gr.Radio(
                        ['fixed', 'increment', 'decrement', 'randomize'],
                        value='fixed', label="Kontrol Seed"
                    )
                steps = gr.Slider(
                    minimum=1, maximum=150, step=1, value=60,
                    label="Steps"
                )
                cfg = gr.Slider(
                    minimum=1.0, maximum=20.0, step=0.1, value=9.0,
                    label="CFG Scale"
                )
                sampler_name = gr.Dropdown(
                    [
                        'dpmpp_3m_sde', 'euler', 'euler_ancestral', 'heun',
                        'dpm_fast', 'dpm_adaptive', 'dpmpp_2s_ancestral',
                        'dpmpp_sde', 'dpmpp_2m', 'dpmpp_2m_sde',
                        'ddpm', 'lcm', 'ddim', 'uni_pc'
                    ],
                    value='dpmpp_3m_sde', label="Sampler Name"
                )
                scheduler_name = gr.Dropdown(
                    ['karras', 'simple', 'sgm_uniform', 'exponential',
                     'ddim_uniform', 'normal'],
                    value='karras', label="Scheduler"
                )
                denoise = gr.Slider(
                    minimum=0.0, maximum=1.0, step=0.05, value=1.0,
                    label="Denoise"
                )

            run_button = gr.Button("Generate Image", variant="primary")


        # --- RIGHT COLUMN (OUTPUT) ---
        with gr.Column(scale=3):
            with gr.Tabs():
                with gr.TabItem("Hasil Gambar"):
                    output_gallery = gr.Gallery(
                        label="Generated Images", show_label=False,
                        elem_id="gallery", columns=2, object_fit="contain", height="auto"
                    )
                    # New output for the ZIP file download link
                    zip_output_file = gr.File(
                        label="Download Semua sebagai .zip", visible=False
                    )
                    status_text = gr.Textbox(label="Status", lines=2, interactive=False)


    # --- Button Action ---
    run_button.click(
        fn=generate_image,
        inputs=[
            checkpoint_name, custom_checkpoint_url,
            lora_name, strength_model, strength_clip,
            positive_prompt, negative_prompt,
            width, height, batch_size,
            seed_value, control_after_generate,
            steps, cfg, sampler_name, scheduler_name, denoise,
            device_choice
        ],
        outputs=[output_gallery, seed_value, zip_output_file, status_text]
    )


demo.launch()